import json
import numpy as np
import pandas as pd
from dataclasses import dataclass
from typing import Tuple, List, Dict, Union, Set, NewType, Any
from Levenshtein import distance as levenshtein_distance


def lev_to_original_error(error_cell: Tuple[int, int],
                          old_error_cells: List[Tuple[int, int]],
                          df_dirty: pd.DataFrame) -> List[float]:
    """
    Bei mehreren unicode-encodeten Suggestions müssen wir eine Suggestion auswählen. Unser Maß hierzu ist
    lev(ursprünglicher Fehler, Fehler aus dem die Regel erstellt wurde). Allgemein gibt es mehrere Fehler, aus denen
    die Regel stammt.
    @param error_cell: Coordinates of the error currently being corrected.
    @param old_error_cells: List of Coordinates of the errors whose corrections were used to create the correcting rule.
    @param df_dirty: Table that is being cleaned.
    @return: Mean levenshtein distance between the error being corrected and the errors used to create the correcting
    rule.
    """
    distances = []
    error_value = df_dirty.iloc[error_cell]
    for old_error_cell in old_error_cells:
        old_error_value = df_dirty.iloc[old_error_cell]
        distances.append(levenshtein_distance(error_value, old_error_value))
    return distances


def lev_to_original_corrections(correction_suggestion: str,
                                old_error_cells: List[Tuple[int, int]],
                                labeled_cells: Dict[Tuple[int, int], List]) -> List[float]:
    """
    Wenn lev_to_original_error keine minimale Distanz birgt, berechnen wir die Levenshtein-Distanz zwischen der ur-
    sprünglichen Korrektur, der zur Operation geführt hat, und dem Korrekturvorschlag.
    @param correction_suggestion: Suggestion to correct the current error
    @param old_error_cells: List of Coordinates of the errors whose corrections were used to create the correcting rule
    @param labeled_cells: Dictionary containing user input
    @return: List of levenshtein distances.
    """
    distances = []
    old_corrections = [labeled_cells[cell] for cell in old_error_cells]
    for old_correction in old_corrections:
        distances.append(levenshtein_distance(correction_suggestion, old_correction))
    return distances


CorrectionSuggestion = NewType('CorrectionSuggestion', str)
FeatureType = NewType('FeatureType', str)
Suggestions = NewType('Suggestions', List[Dict[CorrectionSuggestion, Dict[FeatureType, Any]]])


@dataclass
class ValueSuggestions:
    """A class to hold the suggestions generated by the Value Feature-Generator."""
    cell: Tuple[int, int]
    suggestions: Suggestions
    model_types = ["identity_remover",
                   "unicode_remover",
                   "identity_adder",
                   "unicode_adder",
                   "identity_replacer",
                   "unicode_replacer",
                   "identity_swapper",
                   "unicode_swapper"]

    @property
    def identity_suggestions(self) -> List[Dict[str, Suggestions]]:
        return [self.suggestions[0], self.suggestions[2], self.suggestions[4], self.suggestions[6]]

    @property
    def n_identity_suggestions(self) -> int:
        return sum([len(suggestions) for suggestions in self.identity_suggestions])

    @property
    def unicode_suggestions(self) -> List[Dict[str, Suggestions]]:
        return [self.suggestions[1], self.suggestions[3], self.suggestions[5], self.suggestions[7]]

    @property
    def n_unicode_suggestions(self) -> int:
        return sum([len(suggestions) for suggestions in self.unicode_suggestions])

    @property
    def unique_identity_suggestions(self) -> Set[str]:
        return {s for suggestion in self.identity_suggestions for s in suggestion.keys()}

    @property
    def unique_unicode_suggestions(self) -> Set[str]:
        return {s for suggestion in self.unicode_suggestions for s in suggestion.keys()}

    def certain_model_type_indices_and_suggestions(self, feature: str) -> Tuple[List[int], List[str]]:
        """Index of model types that make a certain suggestion."""
        indices = []
        certain_suggestions = []
        for i, model_suggestions in enumerate(self.suggestions):
            for suggestion, features in model_suggestions.items():
                if features[feature] == 1:
                        indices.append(i)
                        certain_suggestions.append(suggestion)
        return indices, certain_suggestions

    def n_certain_suggestions(self, feature: str) -> int:
        """Number of suggestions with probability 1.0"""
        return sum([1 for model_suggestions in self.suggestions for features in model_suggestions.values() if features[feature] == 1])

    def get_certain_suggestions(self, feature: str) -> List:
        """Return all certain suggestions."""
        return [s for model_suggestions in self.suggestions for s, features in model_suggestions.items() if features[feature] == 1]

    def n_certain_unicode_suggestions(self, feature: str) -> int:
        """Number of unicode suggestions with probability 1.0"""
        return sum([1 for model_suggestions in self.unicode_suggestions for features in model_suggestions.values() if features[feature] == 1])

    def rule_based_suggestion_v1(self, d) -> Union[str, None]:
        """
        Cleaning heuristic to determine the best rule-based suggestion. Documentation on this can be found in
        the experiment from 2022W38.
        """
        if self.n_certain_suggestions('encoded_string_frequency') == 0:  # No certain suggestion at all.
            return None

        if self.n_certain_suggestions('encoded_string_frequency') == 1:  # Use the one certain suggestion.
            choice = [suggestion for model_suggestions in self.suggestions for suggestion, features in model_suggestions.items() if features['encoded_string_frequency'] == 1]
            if len(choice) > 1:
                raise ValueError(f"More than one certain suggestion: {choice}")
            choice = choice[0]

        elif self.n_certain_unicode_suggestions('encoded_string_frequency') == 1:  # Use the one certain unicode-encoded suggestion.
            # Das funktioniert in der Praxis nicht perfekt. Ich bekomme auf rayyan z.B. "1/13" als Vorschlag, obwohl ich
            # einen datestring %m/%d/%y erwarte.
            choice = [suggestion for model_suggestions in self.unicode_suggestions for suggestion, features in model_suggestions.items() if features['encoded_string_frequency'] == 1]
            if len(choice) > 1:
                raise ValueError(f"More than one certain suggestion: {choice}")
            choice = choice[0]

        else:  # sum up the probabilities of both encodings of all certain corrections and take the max.
            suggestion_sums = {}
            indices, suggestions = self.certain_model_type_indices_and_suggestions('encoded_string_frequency')
            for i, s in zip(indices, suggestions):
                if i % 2 == 0:
                    corresponding_index = i + 1
                else:
                    corresponding_index = i - 1
                corresponding_features = self.suggestions[corresponding_index].get(s, {})
                corresponding_score = corresponding_features.get('encoded_string_frequency', 0)
                if suggestion_sums.get(s) is None:
                    suggestion_sums[s] = self.suggestions[i][s]['encoded_string_frequency'] + corresponding_score
                else:
                    suggestion_sums[s] += self.suggestions[i][s]['encoded_string_frequency'] + corresponding_score
            choice = max(suggestion_sums, key=suggestion_sums.get)
        return choice

    def rule_based_suggestion_v2(self, d) -> Union[str, None]:
        """
        Heuristic to reduce the list of possible suggestions to one, rule-based suggestion. This version has been
        developed following Thorsten's feedback. It is documented in 2022W40.
        """
        if self.n_identity_suggestions > 0:  # exact matches exist.
            if len(self.unique_identity_suggestions) == 1:
                return list(self.unique_identity_suggestions)[0]
            return None
        if self.n_unicode_suggestions == 1:
            # tritt nie ein -- es gibt immer mindestens eine Operation + swapper, zwischen denen man entscheidet.
            suggestions = [(s, cells) for model in self.unicode_suggestions for s, features in model.items() for cells in features['error_cells']][0]
            if len(suggestions) > 1:
                raise ValueError('Das darf nicht sein, wenn n_unicode_suggestions == 1 gilt.')
            correction, error_cells = suggestions[0]
            # TODO Check bauen, dass die Operation auf allen gelabelten Daten funktioniert.
            return correction
        elif self.n_unicode_suggestions > 1:
            if len(self.unique_unicode_suggestions) == 1:
                return list(self.unique_unicode_suggestions)[0]

            # Was machen wir, wenn der selbe Reinigungsvorschlag aus unterschiedlichen Regeln gemacht wird?
            distances_to_errors = [(s, lev_to_original_error(self.cell, cells, d.dataframe)) for s in self.unicode_suggestions for features in s.values() for cells in features['error_cells']]
            mean_distances = [(s, np.mean(distances)) for s, distances in distances_to_errors]
            sorted_mean_distances = sorted(mean_distances, key=lambda x: x[1])
            shortest_distance = sorted_mean_distances[0][1]

            shortest_suggestions = [t[0] for t in sorted_mean_distances if t[1] == shortest_distance]
            if len(shortest_suggestions) == 1:
                return list(sorted_mean_distances[0][0].keys())[0]
            else:
                distances_to_corrections = [(s, lev_to_original_corrections(s, features['error_cells'], d.labeled_cells)) for sug in shortest_suggestions for s, features in sug.items()]
                mean_distances = [(c, np.mean(distances)) for c, distances in distances_to_corrections]
                sorted_mean_distances = sorted(mean_distances, key=lambda x: x[1])
                shortest_distance = sorted_mean_distances[0][1]

                shortest_suggestions = [t[0] for t in sorted_mean_distances if t[1] == shortest_distance]
                if len(shortest_suggestions) == 1:
                    return sorted_mean_distances[0][0]
                return sorted_mean_distances[0][0]  # random choice
        return None


def assemble_cleaning_suggestion(transformation_string: str, model_name: str, old_value: str) -> Union[str, None]:
    """
    Use the operation encoded in transform_string and the model_name to identify the operation to transform old_value
    into a cleaning suggestion
    @param transformation_string: the encoded transformation.
    @param model_name: operation name, which is adder, remover, replacer or swapper.
    @param old_value: the erroneous value.
    @return: a cleaning suggestion.
    """
    index_character_dictionary = {i: c for i, c in enumerate(old_value)}
    transformation = json.loads(transformation_string)
    for change_range_string in transformation:
        change_range = json.loads(change_range_string)
        if model_name in ["remover", "replacer"]:
            for i in range(change_range[0], change_range[1]):
                index_character_dictionary[i] = ""
        if model_name in ["adder", "replacer"]:
            ov = "" if change_range[0] not in index_character_dictionary else \
                index_character_dictionary[change_range[0]]
            index_character_dictionary[change_range[0]] = transformation[change_range_string] + ov
    new_value = ""
    try:
        for i in range(len(index_character_dictionary)):
            new_value += index_character_dictionary[i]
    except KeyError:  # not possible to transform old_value.
        new_value = None
    return new_value
