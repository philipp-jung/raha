{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baran Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import IPython.display\n",
    "\n",
    "import raha\n",
    "import datetime\n",
    "from ruska import Ruska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'dataset': 'adult', \n",
    "     'error_fraction': 0.1,\n",
    "     'n_rows': None,\n",
    "     'labeling_budget': 20,\n",
    "     'feature_generators': ['vicinity', 'value', 'domain'],\n",
    "     'vicinity_orders': [1],\n",
    "     'classification_model': 'ABC',\n",
    "     'n_best_pdeps': 5,\n",
    "     \"vicinity_feature_generator\": 'pdep',\n",
    "     \"run\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized dataset\n",
      "initialized models\n",
      "updated\n",
      "generated\n",
      "{'result': {'precision': 0.8283777434727163, 'recall': 0.2527027027027027, 'f1': 0.3872668225105509}}\n",
      "updated\n",
      "generated\n",
      "{'result': {'precision': 0.6132093497229476, 'recall': 0.39426699426699424, 'f1': 0.4799481568256025}}\n",
      "updated\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hf/v_gw8jb14hl89x0x8g88y9pr0000gn/T/ipykernel_46529/4244567518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'updated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_corrections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/raha/raha/correction.py\u001b[0m in \u001b[0;36mgenerate_features\u001b[0;34m(self, d, synchronous)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mfeature_generation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0margs_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocess_args_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_generator_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m                 \u001b[0mfeature_generation_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/raha/raha/correction.py\u001b[0m in \u001b[0;36m_feature_generator_process\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    584\u001b[0m                             \u001b[0med\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_dictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                             \u001b[0mn_best_pdeps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_BEST_PDEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                             use_pdep_feature=self.USE_PDEP_FEATURE)\n\u001b[0m\u001b[1;32m    587\u001b[0m                     \u001b[0mpdep_vicinity_corrections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdep_corrections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/raha/raha/pdep.py\u001b[0m in \u001b[0;36mpdep_vicinity_based_corrector\u001b[0;34m(inverse_sorted_gpdeps, counts_dict, ed, n_best_pdeps, use_pdep_feature)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;31m# like this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# I get the highest gpdep score per correction this way, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhighest_conditional_probabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mhighest_conditional_probabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if c[\"dataset\"] in [\"bridges\", \"cars\", \"glass\", \"restaurant\"]:  # renuver dataset\n",
    "    rate_formatted = int(str(c[\"error_fraction\"]).split(\".\")[1])\n",
    "    run = c[\"run\"] + 1\n",
    "    data_dict = {\n",
    "        \"name\": c[\"dataset\"],\n",
    "        \"path\": f\"../datasets/renuver/{c['dataset']}/{c['dataset']}_{rate_formatted}_{run}.csv\",\n",
    "        \"clean_path\": f\"../datasets/renuver/{c['dataset']}/clean.csv\",\n",
    "    }\n",
    "elif c[\"dataset\"] in [\"beers\", \"flights\", \"hospital\", \"tax\", \"toy\"]:\n",
    "    data_dict = {\n",
    "        \"name\": c[\"dataset\"],\n",
    "        \"path\": f\"../datasets/{c['dataset']}/dirty.csv\",\n",
    "        \"clean_path\": f\"../datasets/{c['dataset']}/clean.csv\",\n",
    "    }\n",
    "elif c[\"dataset\"] in [\"adult\", \"breast-cancer\", \"letter\", \"nursery\"]:\n",
    "    rate_formatted = int(c[\"error_fraction\"] * 10)\n",
    "    data_dict = {\n",
    "        \"name\": c[\"dataset\"],\n",
    "        \"path\": f\"../datasets/{c['dataset']}/MCAR/dirty_{rate_formatted}.csv\",\n",
    "        \"clean_path\": f\"../datasets/{c['dataset']}/clean.csv\",\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(\"Unknown Dataset.\")\n",
    "\n",
    "data = raha.Dataset(data_dict, n_rows=c[\"n_rows\"])\n",
    "data.detected_cells = dict(data.get_actual_errors_dictionary())\n",
    "app = raha.Correction()\n",
    "app.LABELING_BUDGET = c[\"labeling_budget\"]\n",
    "app.VERBOSE = False\n",
    "app.FEATURE_GENERATORS = c[\"feature_generators\"]\n",
    "app.CLASSIFICATION_MODEL = c[\"classification_model\"]\n",
    "app.VICINITY_ORDERS = c[\"vicinity_orders\"]\n",
    "app.VICINITY_FEATURE_GENERATOR = c[\"vicinity_feature_generator\"]\n",
    "app.N_BEST_PDEPS = c[\"n_best_pdeps\"]\n",
    "\n",
    "d = app.initialize_dataset(data)\n",
    "print('initialized dataset')\n",
    "app.initialize_models(d)\n",
    "print('initialized models')\n",
    "while len(d.labeled_tuples) < app.LABELING_BUDGET:\n",
    "    app.sample_tuple(d, random_seed=None)\n",
    "    app.label_with_ground_truth(d)\n",
    "    app.update_models(d)\n",
    "    print('updated')\n",
    "    app.generate_features(d, synchronous=True)\n",
    "    print('generated')\n",
    "    app.predict_corrections(d)\n",
    "\n",
    "    p, r, f = d.get_data_cleaning_evaluation(d.corrected_cells)[-3:]\n",
    "    print({\"result\": {\"precision\": p, \"recall\": r, \"f1\": f}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
