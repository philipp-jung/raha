{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baran Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import IPython.display\n",
    "\n",
    "import raha\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_delta(delta: datetime.timedelta):\n",
    "    hours, remainder = divmod(delta.total_seconds(), 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    h = f'{int(hours)}h ' if hours > 0 else ''\n",
    "    m = f'{int(minutes)}m ' if minutes > 0 else ''\n",
    "    s = f'{int(seconds)}s'\n",
    "    \n",
    "    return h+m+s\n",
    "\n",
    "def estimate_time_to_finish(times: list, current_run_i: int, total_runs: int):\n",
    "    deltas = []\n",
    "    i = 1\n",
    "    \n",
    "    while i+1 <= len(times):\n",
    "        deltas.append(times[i] - times[i-1])\n",
    "        i += 1\n",
    "        \n",
    "    avg = sum(deltas, datetime.timedelta())/len(deltas)\n",
    "    return f'Run {current_run_i}/{total_runs}. {format_delta(avg)} per run, estimate {format_delta(avg*(total_runs - current_run_i))} to finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars_1 = {\"name\": \"cars_1\",\n",
    "         \"path\": \"../datasets/cars_1/dirty.csv\",\n",
    "         \"clean_path\": \"../datasets/cars_1/clean.csv\"}\n",
    "\n",
    "cars_2 = {\"name\": \"cars_2\",\n",
    "         \"path\": \"../datasets/cars_2/dirty.csv\",\n",
    "         \"clean_path\": \"../datasets/cars_2/clean.csv\"}\n",
    "\n",
    "cars_3 = {\"name\": \"cars_3\",\n",
    "         \"path\": \"../datasets/cars_3/dirty.csv\",\n",
    "         \"clean_path\": \"../datasets/cars_3/clean.csv\"}\n",
    "\n",
    "cars_4 = {\"name\": \"cars_4\",\n",
    "         \"path\": \"../datasets/cars_4/dirty.csv\",\n",
    "         \"clean_path\": \"../datasets/cars_4/clean.csv\"}\n",
    "\n",
    "cars_5 = {\"name\": \"cars_5\",\n",
    "         \"path\": \"../datasets/cars_5/dirty.csv\",\n",
    "         \"clean_path\": \"../datasets/cars_5/clean.csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hf/v_gw8jb14hl89x0x8g88y9pr0000gn/T/ipykernel_5383/4189112897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_with_ground_truth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_corrections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/raha/raha/correction.py\u001b[0m in \u001b[0;36mgenerate_features\u001b[0;34m(self, d, synchronous)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 vicinity_gpdeps = pdep.calc_all_gpdeps(d.vicinity_models[o],\n\u001b[1;32m    641\u001b[0m                         d.repaired_dataframe)\n\u001b[0;32m--> 642\u001b[0;31m                 \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_vicinity_gpdeps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert_and_sort_gpdeps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvicinity_gpdeps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# train imputer model for each column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/raha/raha/pdep.py\u001b[0m in \u001b[0;36minvert_and_sort_gpdeps\u001b[0;34m(gpdeps)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msorted\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdescendingly\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgpdep\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0minverse_gpdeps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrhs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpdeps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlhs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpdeps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "datasets = range(1,6)\n",
    "runs = range(1,6)\n",
    "\n",
    "duration_experiment = len(datasets) * len(runs)\n",
    "times = [datetime.datetime.now()]\n",
    "i = 1\n",
    "\n",
    "for run in runs:\n",
    "    for dataset in datasets:\n",
    "        data_dict = {\"name\": \"cars_{0}_{1}\".format(run, dataset),\n",
    "                     \"path\": \"../datasets/renuver/cars/cars_{0}_{1}.csv\".format(run, dataset),\n",
    "                     \"clean_path\": \"../datasets/renuver/cars/clean.csv\"\n",
    "                    }\n",
    "\n",
    "        data = raha.Dataset(data_dict)\n",
    "        data.detected_cells = dict(data.get_actual_errors_dictionary())\n",
    "        app = raha.Correction()\n",
    "        app.LABELING_BUDGET = 20\n",
    "        app.VERBOSE = False\n",
    "        app.FEATURE_GENERATORS = ['value', 'domain', 'vicinity']\n",
    "        app.CLASSIFICATION_MODEL = \"ABC\"\n",
    "        app.VICINITY_ORDERS = [1, 2]\n",
    "        app.VICINITY_FEATURE_GENERATOR = 'pdep'\n",
    "        app.N_BEST_PDEPS = 5\n",
    "        app.GPDEP_CORRECTION_SCORE_THRESHOLD = 0\n",
    "\n",
    "\n",
    "        d = app.initialize_dataset(data)\n",
    "        app.initialize_models(d)\n",
    "\n",
    "        while len(d.labeled_tuples) < app.LABELING_BUDGET:\n",
    "            app.sample_tuple(d, random_seed=None)\n",
    "            app.label_with_ground_truth(d)\n",
    "            app.update_models(d)\n",
    "            app.generate_features(d, synchronous=True)\n",
    "            app.predict_corrections(d, random_seed=None)\n",
    "\n",
    "        p, r, f = d.get_data_cleaning_evaluation(d.corrected_cells)[-3:]\n",
    "        result = {'dataset': d.name, \n",
    "                  'run': run,\n",
    "                  'precision': p, 'recall': r, 'f1': f}                    \n",
    "        results.append(result)\n",
    "        print(result)\n",
    "\n",
    "        # time estimates for the measurement\n",
    "        times.append(datetime.datetime.now())\n",
    "        print(estimate_time_to_finish(times, i, duration_experiment))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
